name: "no-option/0"
cuda: False
cores: 4
seed: 0

environment:
  name: "ALE/Kangaroo-v5"
  object_centric: True
  reward_mode: env  # env, human, mixed
  prune_concept: default
  exclude_properties: False  # exclude object properties (like position) from feature vector
  framestack: 1
  frameskip: 4
  normalize_observation: True
  normalize_reward: False
  freeze_invisible_obj: False

model:  # if an existing model is reloaded, these parameters are ignored
  options_hierarchy: []  # e.g., [2, 4, 8] means 2 high-level, 4 mid-level, and 8 low-level options
  net_arch: [64, 64]  # the network architecture of each individual option policy
  ppo:
    n_steps: 256
    n_epochs: 4
    batch_size: 256
    gamma: 0.99
    # gae_lambda: 0.95
    clip_range:  # clipping epsilon
      initial_value: 0.1
      schedule_type: linear
    vf_coef: 0.5
    ent_coef: 0.05
    clip_range_vf:
    normalize_advantage: True
    gae_lambda: 0.95

training:
  total_timesteps: 5e7
  learning_rate:  # Adam
    initial_value: 0.001
    schedule_type: exponential
    half_life_period: 0.25

evaluation:
  frequency: 250000
  deterministic: True
  render: False
  early_stop: 1000
