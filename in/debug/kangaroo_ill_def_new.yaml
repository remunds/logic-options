name: "debug"
description: "Rerun kangaroo ill defined experiment."
device: cuda:14
cores: 1
seed: 0

environment:
  name: "ALE/Kangaroo-v5"
  object_centric: True
  reward_mode: human  # env, human, mixed
  framestack: 4
  frameskip: 1
  normalize_observation: True
  normalize_reward: False
  prune_concept: default  # default or external: use pruned focusfile (from default 'focusfiles' dir or external 'baselines_focusfiles' dir. for custom pruning and or docker mount)
  exclude_properties: False  # exclude object properties (like position) from feature vector
  # normalize: True
  freeze_invisible_obj: False

general:
  hierarchy_shape: []  # e.g., [2, 4, 8] means 2 high-level, 4 mid-level, and 8 low-level options
  net_arch: [64, 64]  # the network architecture of each individual policy and value function
  total_timesteps: 5e7
  n_steps: 256
  n_epochs: 4
  batch_size: 256  # decrease if out-of-memory error is observed
  gamma: 0.99
  # clip_range:  # clipping epsilon
  #   initial_value: 0.1
  #   schedule_type: linear
  # vf_coef: 0.5
  # ent_coef: 0.05
  # clip_range_vf:
  normalize_advantage: True
  gae_lambda: 0.95

meta_policy:
  logic: False
  policy_ent_coef: 0.05
  policy_clip_range:  # PPO clipping epsilon
    initial_value: 0.1
    schedule_type: linear
  value_fn_coef: 0.5
  value_fn_clip_range:
  learning_rate:  # Adam
    initial_value: 0.001
    schedule_type: exponential
    half_life_period: 0.25

evaluation:
  frequency: 250000
  n_episodes: 8
  deterministic: True
  render: False
  early_stop_on_no_reward: 1000
